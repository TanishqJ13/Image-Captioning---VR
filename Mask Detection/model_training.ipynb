{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nfrom torch.optim import lr_scheduler\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nfrom torchvision.ops import nms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# yolo = cv2.dnn.readNet('../input/yolo-v3-weights/yolov3.weights', '../input/file123/darknet/darknet/darknet-master/cfg/yolov3.cfg')\n# layer_names = yolo.getLayerNames()\n# output_layers = [layer_names[x[0] - 1] for x in yolo.getUnconnectedOutLayers()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def detect_face(image):\n#     face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n#     plt.imshow(image)\n#     grayscale_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#     faces = face_cascade.detectMultiScale(grayscale_image, 1.2, 7)\n#     for (x,y,w,h) in faces:\n#         img = cv2.rectangle(image,(x,y),(x+w,y+h),(0,255,0),5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def my_yolo(image):\n#     yolo.setInput(cv2.dnn.blobFromImage(image, 0.00392, (416,416), (0,0,0), swapRB = True, crop = False))\n#     out = yolo.forward(output_layers)\n#     confidences = []\n#     boxes = []\n#     width = image.shape[1]\n#     height = image.shape[0]\n#     for curr_out in out:\n#         for detection in curr_out:\n#             scores = detection[5:]\n#             class_id = np.argmax(scores)\n#             confidence = scores[class_id]\n#             if confidence > 0.1 and class_id == 0:\n#                 center_x = int(detection[0] * width)\n#                 center_y = int(detection[1] * height)\n#                 w = int(detection[2] * width)\n#                 h = int(detection[3] * height)\n#                 x = center_x - w / 2\n#                 y = center_y - h / 2\n#                 confidences.append(float(confidence))\n#                 boxes.append([x, y, x + w, y + h])\n#     boxes = torch.tensor(boxes)\n#     confidences = torch.tensor(confidences)\n#     iou_threshold = 0.2\n#     indices = nms(boxes, confidences, iou_threshold)\n#     for i in indices:\n#         cv2.rectangle(image, (torch.round(boxes[i][0]), torch.round(boxes[i][1])), (torch.round(boxes[i][2]), torch.round(boxes[i][3])), (0, 0, 0), 2)\n#         cv2.putText(image, 'person', (torch.round(boxes[i][0]) - 10, torch.round(boxes[i][1]) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 2)\n#     plt.imshow(image)\n#     boxes = [boxes[i] for i in indices]\n#     return boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image = plt.imread('../input/vr-project1-dataset/image1.jpg')\n# boxes = my_yolo(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i in range(len(boxes)):\n#     curr_img = cv2.imread('../input/vr-project1-dataset/image1.jpg')\n#     curr_img = curr_img[int(boxes[i][1]) : int(boxes[i][3]), int(boxes[i][0]) : int(boxes[i][2])]\n#     detect_face(curr_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class data_convert(Dataset):\n    def __init__(self, data):\n        self.dataframe = data\n    \n    def __getitem__(self, ind):\n        return self.dataframe[ind]\n    \n    def __len__(self):\n        return len(self.dataframe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = np.load('../input/vrproj/data.npy')\ntarget = np.load('../input/vrproj/target.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_data = []\n\nfor i in range(len(data)):\n    \n    temp_data = []\n    fin_data = []\n    for j in range(100):\n        curr_data = []\n        for k in range(100):\n            curr_data.append(data[i][j][k][0])\n        temp_data.append(curr_data)\n    fin_data.append(temp_data)\n    \n    if target[i][0] == 0:\n        combined_data.append((fin_data, 1))\n    else:\n        combined_data.append((fin_data, 0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_generator(curr_batch):\n    images = []\n    labels = []\n    for x in curr_batch:\n        images.append(x[0])\n        labels.append(x[1])\n    images = torch.tensor(images, dtype = torch.float32)\n    labels = torch.tensor(labels, dtype = torch.long)\n    return images, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = data_convert(combined_data)\ndata_train, data_test = train_test_split(data, test_size = 0.1, shuffle = True)\ndata_train = torch.utils.data.DataLoader(data_train, batch_size = 32, shuffle = True, collate_fn = batch_generator)\ndata_test = torch.utils.data.DataLoader(data_test, batch_size = 32, shuffle = True, collate_fn = batch_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 200, 3, 1, 0)\n        self.pool1 = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(200, 100, 3, 1, 0)\n        self.pool2 = nn.MaxPool2d(2, 2)\n        self.fc1 = nn.Linear(23 * 23 * 100, 50)\n        self.fc2 = nn.Linear(50, 2)\n        self.soft = nn.Softmax(dim=1)\n        self.drop = nn.Dropout()\n\n    def forward(self, x):\n        x = self.pool1(F.relu(self.conv1(x)))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = x.view(-1, 23 * 23 * 100)\n        x = self.drop(x)\n        x = F.relu(self.fc1(x))\n        x = self.soft(self.fc2(x))\n        return x\n\nnet = Net()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet.to(my_device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr = 0.001,momentum=0.9)\ncriterion.to(my_device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_losses_test = []\nvalidation_losses_train = []\n\nfor epoch in range(100): \n    running_loss_test = 0.0\n    running_loss_train = 0.0\n    for i, data in enumerate(data_train, 0):\n        inputs, labels = data\n        inputs, labels = inputs.to(my_device), labels.to(my_device)\n        optimizer.zero_grad()\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss_train += loss.item()\n    validation_losses_train.append((running_loss_train * 32)/len(data_train))\n    \n    with torch.no_grad():\n        for data in data_test:\n            inputs,labels = inputs.to(my_device), labels.to(my_device)\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            running_loss_test += loss.item()\n        validation_losses_test.append((running_loss_test * 32)/len(data_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(validation_losses_train, label = 'validation_train')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(validation_losses_test, label = 'validation_test')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0.0\ntotal = 0.0\nwith torch.no_grad():\n    for data in data_test:\n        inputs, labels = inputs.to(my_device), labels.to(my_device)\n        outputs = net(inputs)\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n\nprint('Accuracy of the network on the test images: %d %%' % (100.0 * correct / total))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = './mask_classifier.pth'\ntorch.save(net.state_dict(), PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Net()\nnet.load_state_dict(torch.load(PATH))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}